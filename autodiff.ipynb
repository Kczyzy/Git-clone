{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e053fa0c-c6d6-417a-8139-60c99f78bc88",
   "metadata": {},
   "source": [
    "## Automatic differentiation with JAX and PyTorch for gradient and Hessian computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a120a65-8416-4a39-a6e4-d35ddbe7f657",
   "metadata": {},
   "source": [
    "### JAX\n",
    "You might want to begin by installing JAX. This is done via pip; see instructions here: https://github.com/google/jax#installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f59f19c3-0ae6-4116-b1ba-3ef9029ad2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp # this is a thin wrapper to NumPy within JAX\n",
    "from jax import grad, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f2fae3e-56fb-4be5-8243-aee20dbe19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 2D example\n",
    "x1 = np.linspace(-5,5,100)\n",
    "x2 = np.linspace(-5,5,100)\n",
    "x1v,x2v = np.meshgrid(x1, x2)\n",
    "x = np.column_stack((x1v.reshape(-1,1), x2v.reshape(-1,1)))\n",
    "f = lambda x: (x[...,0] - 2)**2 + (x[...,1] - 1)**2 # this is our function we want to differentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05dcffe3-f9d8-4b10-a07e-0fee3f62f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient at x1: [-14. -12.]\n",
      "normalized gradient at x1: [-0.7592566  -0.65079135]\n"
     ]
    }
   ],
   "source": [
    "# computing gradient\n",
    "x_ = x[0] # point at which we want the gradient\n",
    "gradf = grad(f)  # Obtain its gradient function\n",
    "print(f'gradient at x1: {gradf(x_)}')\n",
    "print(f'normalized gradient at x1: {gradf(x_) / np.linalg.norm(gradf(x_))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25bd34df-9b6e-443e-8e69-7a3523cb39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian at x1: [[2. 0.]\n",
      " [0. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# computing Hessian\n",
    "hess = hessian(f)#\n",
    "print(f'Hessian at x1: {hess(x_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6f727fa-bbd5-4fe6-adc6-e1fbfa474697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'jaxlib.xla_extension.Array'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy arrays\n",
    "B = hess(x_)\n",
    "B_np = np.asarray(hess(x_))\n",
    "print(type(B)) # JAX Array type\n",
    "print(type(B_np)) # NumPy array type. Do this if the rest of your code uses NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbcbb97-75cb-4624-9d4c-94e65f976f42",
   "metadata": {},
   "source": [
    "### Autodiff using PyTorch.\n",
    "While JAX is great, its NumPy wrapper can sometimes be limited. PyTorch is another alternative (that I know of). However, this option is not recommended unless you are already using PyTorch for some other reason.\n",
    "Begin by installing PyTorch via pip: see https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "534ba8b9-1429-44bf-8e2c-eac653b8b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd.functional import jacobian, hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07a4ea1d-f90a-4e47-b57e-888a027cf04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient tensor([-14., -12.])\n",
      "Hessian tensor([[2., 0.],\n",
      "        [0., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor(x_, dtype=torch.float32)\n",
    "# gradient\n",
    "g = jacobian(f, x_tensor)\n",
    "print(f'Gradient {g}')\n",
    "\n",
    "H = hessian(f, x_tensor)\n",
    "print(f'Hessian {H}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "552d151a-ab56-4917-9c8f-201415e7848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Convert to NumPy array\n",
    "g_np = g.numpy()\n",
    "H_np = H.numpy()\n",
    "print(type(g))\n",
    "print(type(g_np))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
